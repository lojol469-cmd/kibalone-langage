#!/usr/bin/env python3
"""
Script de tÃ©lÃ©chargement du modÃ¨le LLM pour Kibali
ModÃ¨le choisi: microsoft/phi-1_5 (1.3GB, rapide, bon pour le raisonnement)
"""

import os
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM

def download_phi_model():
    """TÃ©lÃ©charge le modÃ¨le Phi-1.5"""
    model_name = "microsoft/phi-1_5"
    local_path = Path("./models/phi-1_5")

    print(f"ğŸš€ TÃ©lÃ©chargement du modÃ¨le: {model_name}")
    print(f"ğŸ“ Destination: {local_path.absolute()}")
    print("â³ Cela peut prendre quelques minutes...")

    # CrÃ©er le dossier si nÃ©cessaire
    local_path.parent.mkdir(exist_ok=True)

    try:
        # TÃ©lÃ©charger le tokenizer
        print("ğŸ“¥ TÃ©lÃ©chargement du tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(model_name)

        # TÃ©lÃ©charger le modÃ¨le
        print("ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le...")
        model = AutoModelForCausalLM.from_pretrained(model_name)

        # Sauvegarder localement
        print("ğŸ’¾ Sauvegarde locale...")
        model.save_pretrained(local_path)
        tokenizer.save_pretrained(local_path)

        print("âœ… ModÃ¨le tÃ©lÃ©chargÃ© avec succÃ¨s!")
        print(f"ğŸ“Š Taille approximative: 1.3GB")
        print(f"ğŸ”§ ModÃ¨le prÃªt pour l'intÃ©gration dans le cerveau des cellules")

    except Exception as e:
        print(f"âŒ Erreur lors du tÃ©lÃ©chargement: {e}")
        return False

    return True

if __name__ == "__main__":
    success = download_phi_model()
    if success:
        print("\nğŸ‰ PrÃªt pour l'intÃ©gration dans kibali.py!")
    else:
        print("\nâŒ Ã‰chec du tÃ©lÃ©chargement. VÃ©rifiez votre connexion internet.")